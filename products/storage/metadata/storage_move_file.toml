region_tag = ["storage_move_file"]
creation_date = 2023-12-06
modification_date = 2023-12-06
title = "Move/rename file in Google Cloud Storage bucket"
description = "Moves or renames a file inside a storage bucket. Not suitable to move files between buckets."
standalone = true
deprecated = false
# What kinds of preconditions needs to be met. Natural language. (optional)
requirements_desc = "The bucket and the file must exist. User needs to have write permission to the bucket."
# What will happen when the code sample in the region tag gets executed. Natural Language. (optional)
effects_desc = "File is moved/renamed."

[requirements]
# List of services that need to be enabled for the sample (and tests) to work.
# The system will use `gcloud services enable <api>` to turn them all on.
apis = [
    'storage.googleapis.com'
]
# What permissions are needed for the code sample to properly work.
required_permissions = [
    'storage.objects.update',
    'storage.objects.get',
    'storage.objects.create'
]
# What roles can be used to provide neccessary permissions.
# Those should be predefined roles, but in case you want to use a custom role, use it in the form of:
# projects/<project_name>/roles/<role_name>
# So it is clear that it is a custom role.
required_roles = [
    'roles/storage.objectUser'
]



[[tests]]
# Indicates if the resoruces prepared in the setup section can be shared between tests.
# This is used to tests that don't alter the resources (i.e. listing PubSub topics).
# If set to false, setup and cleanup will happen for each language separately.
# If set to true, setup and cleanup will happen only once.
shared_resources = false

# How many tests from this set can be executed at the same time. Needed in case of limited resources.
# Different versions of a language are treated as separate language.
parallel_limit = 16

[tests.variables]
# The series of #### gets replaced by random string to generate unique IDs.
# A different value is prepared for each test language. Different versions of a language
# count as different languages.
BUCKET_NAME = 'test-bucket-#####'
FILE_NAME = 'test-file-#####'
NEW_FILE_NAME = 'test-file-#####'

[tests.setup]
# Terraform setup will implicitly execute `terraform init` and `terraform apply`
# passing all variables from above as `-var="<key> = <value>"
# Passing the files that are to be applied to set up the environment
terraform = ["tf/storage_move_file/single_bucket_move.tf"]

[tests.check]
# Using ! to fail if there is our template present in the returned list
command = "gsutil ls gs://$BUCKET_NAME/ | grep $NEW_FILE_NAME"

[tests.cleanup]
# Make sure the file is deleted. If the command can fail, use `|| true` to supress the failure.
# Since Terraform was used to set up the environment, it will be automatically used to clean up using
# `terraform destroy`. However, since some resources might no longer be under Terraform control, we have an option to
# execute some commands before `terraform destroy` takes place.

commands = ["gsutil rm -f gs://$BUCKET_NAME/$NEW_FILE_NAME || true"]

[tests.python]
# We can specify which versions of a language we want to test against.
versions = ["3.8", "3.12"]
# Legacy tests skip setup, cleanup and check. They only execute the method pointed to and check if it failed.
legacy = false
file = "../python/storage_move_file.py"
method = "move_blob"
# Parameters can be strings, integers and floats. Define appropriate value in TOML - it supports ints and floats!
parameters = ["$BUCKET_NAME", "$FILE_NAME", "$BUCKET_NAME", "$NEW_FILE_NAME"]
# Those packages will be installed before executing the Python sample.
requirements = "../python/requirements.txt"

[tests.java]
versions = ["11", "17", "21"]
# Legacy tests skip setup, cleanup and check. They only execute the method pointed to and check if it failed.
legacy = false
# Package name of the sample to be tested.
package_name = "object"
# Name of the class can be derived from the file name.
file = "../java/src/main/java/MoveObject.java"
# The method has to be public and static, so it can be called from outside the class
method = "moveObject"
# Parameters can be strings, integers and floats. Define appropriate value in TOML - it supports ints and floats!
parameters = ["$PROJECT_ID", "$BUCKET_NAME", "$FILE_NAME", "$BUCKET_NAME", "$NEW_FILE_NAME"]
# Those packages will be installed before compiling and executing the Java sample.
pom = "../java/pom.xml"

[[tests]] # Second set of tests to check moving between buckets

shared_resources = false
parallel_limit = 16

[tests.variables]
BUCKET_NAME = 'test-bucket-#####'
NEW_BUCKET_NAME = 'test-bucket-#####'
FILE_NAME = 'test-file-#####'
NEW_FILE_NAME = 'test-file-#####'


[tests.setup]
terraform = ["tf/storage_move_file/move_between_buckets.tf"]

[tests.check]
command = "gsutil ls gs://$NEW_BUCKET_NAME/ | grep $NEW_FILE_NAME"

[tests.cleanup]
commands = ["gsutil rm -f gs://$NEW_BUCKET_NAME/$NEW_FILE_NAME || true"]

[tests.python]
versions = ["3.8", "3.12"]
legacy = false
file = "../python/storage_move_file.py"
method = "move_blob"
parameters = ["$BUCKET_NAME", "$FILE_NAME", "$NEW_BUCKET_NAME", "$NEW_FILE_NAME"]
requirements = "../python/requirements.txt"

[tests.java]
versions = ["11", "17", "21"]
legacy = false
# Package name of the sample to be tested.
package_name = "object"
file = "../java/src/main/java/MoveObject.java"
method = "moveObject"
parameters = ["$PROJECT_ID", "$BUCKET_NAME", "$FILE_NAME", "$NEW_BUCKET_NAME", "$NEW_FILE_NAME"]
pom = "../java/pom.xml"